{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff20774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score,roc_curve,auc,classification_report,roc_auc_score,confusion_matrix\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from mrmr import mrmr_classif, mrmr_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fa6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###selectkbest method\n",
    "def selectkbest_top50(data,label,k=20,score_func=f_classif):\n",
    "    selector = SelectKBest(score_func=score_func, k='all').fit(data,label)\n",
    "    df_scores = pd.DataFrame(selector.scores_)\n",
    "    df_columns = pd.DataFrame(data.columns)\n",
    "    df_feature_scores = pd.concat([df_columns, df_scores], axis=1)\n",
    "    df_feature_scores.columns = ['Feature', 'Score']\n",
    "    feature_names=df_feature_scores.sort_values(by='Score', ascending=False)[:k]['Feature']\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4077909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MRMR method\n",
    "def mrmr_fs(data,label,info,k=50):\n",
    "    \n",
    "    k = min(len(data.columns),k)\n",
    "    if info.split(\",\")[0] == 'classification':\n",
    "        selected_id = mrmr_classif(X=data, y=label, K=k,n_jobs=4)\n",
    "    else:\n",
    "        selected_id = mrmr_regression(X=data, y=label, K=k,n_jobs=4)\n",
    "    feature_names = list(data.loc[:,selected_id].columns)\n",
    "    return feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c13642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cox selection （survival）\n",
    "def cox_selection(x,y):\n",
    "    from lifelines import CoxPHFitter\n",
    "    cph = CoxPHFitter()\n",
    "    ss =[]\n",
    "    df = pd.concat([pd.DataFrame(y,index=x.index),x],axis=1)\n",
    "    for i in range(2,len(df.columns)):\n",
    "        cph.fit(df.iloc[:,[0,1,i]], 'time',event_col='Status')\n",
    "        ss.append(cph.summary['p'])\n",
    "    ss2 = pd.concat(ss)\n",
    "    features = ss2[ss2 <0.05].sort_values()[:50].index\n",
    "    return list(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2dddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TOPK method\n",
    "def pre_screening(data2,label,model,features,cv=5):\n",
    "    #第一步筛选\n",
    "    feature_names = features\n",
    "    data2 = data2[feature_names].to_numpy()\n",
    "    #ifs方法得到前三分类器选择的特征数\n",
    "    clf = model\n",
    "    features_num = min([len(features), 20])\n",
    "    cv_scores = [cross_val_score(clf, data2[:, :i], label, cv=cv, n_jobs=4).mean() for i in range(1, features_num + 1)]\n",
    "    clf_num = list(pd.DataFrame(cv_scores).iloc[:,0].sort_values(ascending=False).index[:5]+1)\n",
    "    return clf_num, cv_scores\n",
    "def train_top3(clf,data,label,clf_num,train_index,test_index,feature_names):\n",
    "    test_accs,estimators,predicts,f_names = {},{},{},{}\n",
    "    mean_accs = []\n",
    "    for j in range(len(clf_num)):    #top3分类器\n",
    "        preds,tests,res,f_name = [],[],[],[]\n",
    "        for i in range(len(train_index)):\n",
    "            xtrain,ytrain = data.iloc[train_index[i],:],label[train_index[i]]\n",
    "            xtest,ytest = data.iloc[test_index[i],:],label[test_index[i]]\n",
    "            xtrain,xtest = xtrain.loc[:,feature_names[:clf_num[j]]],xtest.loc[:,feature_names[:clf_num[j]]]\n",
    "            estimator,test_acc,predict = train_estimator(clf,xtrain,ytrain,xtest,ytest)\n",
    "            tests.append(test_acc),res.append(estimator),preds.append(predict)\n",
    "        mean_accs.append(np.mean(tests))\n",
    "        test_accs[clf_num[j]] = tests\n",
    "        estimators[clf_num[j]] = res\n",
    "        predicts[clf_num[j]] = preds\n",
    "        f_names[clf_num[j]] = feature_names[:clf_num[j]]\n",
    "    #选择得分最高的topk\n",
    "    topk = clf_num[mean_accs.index(max(mean_accs))]\n",
    "    test_accs = test_accs[topk]\n",
    "    estimators = estimators[topk]\n",
    "    predicts = predicts[topk]\n",
    "    f_names = f_names[topk]\n",
    "    return test_accs,estimators,mean_accs,predicts,f_names\n",
    "\n",
    "\n",
    "def train_top3_reg(clf, data, label, clf_num, train_index, test_index, feature_names):\n",
    "    test_accs, estimators, predicts, f_names = {}, {}, {}, {}\n",
    "    mean_accs = []\n",
    "    for j in range(len(clf_num)):  # top3分类器\n",
    "        preds, tests, res, f_name = [], [], [], []\n",
    "        for i in range(len(train_index)):\n",
    "            xtrain, ytrain = data.iloc[train_index[i], :], label[train_index[i]]\n",
    "            xtest, ytest = data.iloc[test_index[i], :], label[test_index[i]]\n",
    "            xtrain, xtest = xtrain.loc[:, feature_names[:clf_num[j]]], xtest.loc[:, feature_names[:clf_num[j]]]\n",
    "            estimator, test_acc, predict = train_estimator_reg(clf, xtrain, ytrain, xtest, ytest)\n",
    "            tests.append(test_acc), res.append(estimator), preds.append(predict)\n",
    "        mean_accs.append(np.mean(tests))\n",
    "        test_accs[clf_num[j]] = tests\n",
    "        estimators[clf_num[j]] = res\n",
    "        predicts[clf_num[j]] = preds\n",
    "        f_names[clf_num[j]] = feature_names[:clf_num[j]]\n",
    "    # 选择得分最高的topk\n",
    "    topk = clf_num[mean_accs.index(max(mean_accs))]\n",
    "    test_accs = test_accs[topk]\n",
    "    estimators = estimators[topk]\n",
    "    predicts = predicts[topk]\n",
    "    f_names = f_names[topk]\n",
    "    return test_accs, estimators, mean_accs, predicts, f_names\n",
    "\n",
    "\n",
    "\n",
    "def train_estimator(clf,xtrain,ytrain,xtest,ytest):\n",
    "    clf = copy.deepcopy(clf)\n",
    "    res = clf.fit(xtrain,ytrain)\n",
    "    predict = res.predict(xtest)\n",
    "    test_acc = accuracy_score(ytest,predict,normalize=True,)\n",
    "    return res,test_acc,predict\n",
    "\n",
    "def train_estimator_reg(clf, xtrain, ytrain, xtest, ytest):\n",
    "    clf2 = copy.deepcopy(clf)\n",
    "    # print(xtrain.dtypes)\n",
    "    # print(xtrain, ytrain)\n",
    "    res = clf2.fit(xtrain, ytrain)\n",
    "    predict = res.predict(xtest)\n",
    "    test_acc = res.score(xtest, ytest)\n",
    "    # print('test_acc: ',test_acc)\n",
    "    return res, test_acc, predict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ad517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###FSS method\n",
    "def FSS_fun(feature_names,clf,data,label,cv,n_jobs=1):\n",
    "    feature_names2 = list(feature_names)\n",
    "    selected_feature = []\n",
    "    max_scores = []\n",
    "    features_num = min([len(feature_names),20])#判断特征数目是否大于20\n",
    "    for i in range(features_num):\n",
    "        cv_scores = []\n",
    "        for feature in feature_names2:\n",
    "            # train_feature = [feature] + selected_feature\n",
    "            train_feature = selected_feature + [feature]\n",
    "            data1 = pd.DataFrame(data.loc[:,train_feature])\n",
    "            cv_score = cross_val_score(clf,data1,label,cv=cv,n_jobs=n_jobs,error_score='raise').mean()\n",
    "            cv_scores.append(cv_score)\n",
    "        max_index = np.array(cv_scores).argmax()\n",
    "        max_score = max(cv_scores)\n",
    "        max_scores.append(max_score)\n",
    "        selected_feature.append(feature_names2[max_index])\n",
    "        feature_names2.remove(feature_names2[max_index])\n",
    "    return selected_feature,max_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00722f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BSS_fun(feature_names,clf,data,label,cv,n_jobs=1):\n",
    "    feature_names2 = list(feature_names)\n",
    "    selected_feature = []\n",
    "    max_scores = []\n",
    "    max_scores.append(cross_val_score(clf,data,label,cv=cv,n_jobs=n_jobs).mean())#计算全部特征下的训练结果\n",
    "    features_num = min([len(feature_names),50])#判断特征数目是否大于50\n",
    "    for i in range(features_num-1):\n",
    "        cv_scores = []\n",
    "        for feature in feature_names2:\n",
    "            train_feature = feature_names2[:] #切片，独立于原列表\n",
    "            train_feature.remove(feature)\n",
    "            data1 = pd.DataFrame(data.loc[:,train_feature])\n",
    "            cv_score = cross_val_score(clf,data1,label,cv=cv,n_jobs=n_jobs).mean()\n",
    "            cv_scores.append(cv_score)\n",
    "        max_index = np.array(cv_scores).argmax()\n",
    "        max_score = max(cv_scores)\n",
    "        max_scores.append(max_score)\n",
    "        selected_feature.append(feature_names2[max_index])\n",
    "        del feature_names2[max_index]\n",
    "    selected_feature.append(feature_names2[0])\n",
    "    selected_feature.reverse() #反向排序\n",
    "    max_scores.reverse()\n",
    "    return selected_feature,max_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235fd78a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T09:45:24.887206Z",
     "start_time": "2024-06-07T09:45:24.868045Z"
    }
   },
   "outputs": [],
   "source": [
    "def df2bp(df):\n",
    "    data = []\n",
    "    for col in df.columns:\n",
    "        trace = {\n",
    "            'type': 'box',\n",
    "            'name': col.replace('test_accuracy', 'accuracy'),\n",
    "            'y': df[col].to_list()\n",
    "        }\n",
    "        data.append(trace)\n",
    "    return data\n",
    "def RSKFold (data,label,n=10,k=5):\n",
    "    train_index = []\n",
    "    test_index = []\n",
    "    kf = RepeatedStratifiedKFold(n_splits=k,n_repeats=n,random_state=10)\n",
    "    for train, test in kf.split(data,label):\n",
    "        train_index.append(train)\n",
    "        test_index.append(test)\n",
    "    return train_index,test_index\n",
    "def RegressionKFold(data, label, n=10, k=5):\n",
    "    train_index = []\n",
    "    test_index = []\n",
    "    kf = RepeatedKFold(n_splits=k, n_repeats=n, random_state=10)\n",
    "    for train, test in kf.split(data, label):\n",
    "        train_index.append(train)\n",
    "        test_index.append(test)\n",
    "    return train_index, test_index\n",
    "\n",
    "def sur_RSKFold (data,label,n=10,k=5):\n",
    "    train_index = []\n",
    "    test_index = []\n",
    "    kf = RepeatedKFold(n_splits=k,n_repeats=n,random_state=10)\n",
    "    for train, test in kf.split(data,label):\n",
    "        train_index.append(train)\n",
    "        test_index.append(test)\n",
    "    return train_index, test_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
