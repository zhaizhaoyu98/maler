{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ff575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB,ComplementNB,MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_bulid(svc, gridsearch_para, clf_name):\n",
    "    grid_cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=10)\n",
    "    grid_model = copy.deepcopy(svc)\n",
    "    param_grid = grid_space(svc, gridsearch_para, clf_name)\n",
    "    grid_search = GridSearchCV(grid_model, param_grid, cv=grid_cv, scoring='r2', n_jobs=5)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dab3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_space(model, gridsearch_para, clf_name):\n",
    "    if clf_name == 'Naive Bayes':\n",
    "        search_space = gridsearch_para\n",
    "    if clf_name == 'SVM':\n",
    "        search_space = {\n",
    "            'C': gridsearch_para['C'],\n",
    "        }\n",
    "        if model.get_params()['kernel'] == 'rbf':\n",
    "            search_space['gamma'] = list(gridsearch_para['gamma']) + ['scale', 'auto']\n",
    "        elif model.get_params()['kernel'] == 'poly':\n",
    "            search_space['gamma'] = list(gridsearch_para['gamma']) + ['scale', 'auto']\n",
    "            search_space['coef0'] = gridsearch_para['coef0']\n",
    "            search_space['degree'] = gridsearch_para['degree']\n",
    "        elif model.get_params()['kernel'] == 'sigmoid':\n",
    "            search_space['gamma'] = list(gridsearch_para['gamma']) + ['scale', 'auto']\n",
    "            search_space['coef0'] = gridsearch_para['coef0']\n",
    "    if clf_name == 'RandomForest':\n",
    "        # 全部转为整数\n",
    "        gridsearch_para_convert = convert_float_to_int(gridsearch_para)\n",
    "        search_space = gridsearch_para_convert\n",
    "    if clf_name == 'Logistic':\n",
    "        search_space = gridsearch_para\n",
    "    if clf_name == 'KNN':\n",
    "        search_space = gridsearch_para\n",
    "    if clf_name == 'XGBoost':\n",
    "        search_space = gridsearch_para\n",
    "    if clf_name == 'lightGBM':\n",
    "        search_space = gridsearch_para\n",
    "    if clf_name == 'Adaboost':\n",
    "        search_space = gridsearch_para\n",
    "    if clf_name == 'DecisionTree':\n",
    "        search_space = gridsearch_para\n",
    "    if clf_name == 'GBDT':\n",
    "        search_space = gridsearch_para\n",
    "    return search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a606238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_class_model(request):\n",
    "    select_child_model = request.POST.get('select_child_model').replace('task_', '')\n",
    "    # gridsearch para\n",
    "    gridsearch_para = {}\n",
    "    grid = request.POST.get('usr_grid')\n",
    "    print('usr_grid:', grid)\n",
    "    if select_child_model == 'naivebayes':\n",
    "        select_model_name = 'Naive Bayes'\n",
    "        alpha, name = (request.POST.get('naivebayes_alpha')), request.POST.get('naivebayes_name')\n",
    "        if grid == 'G': #判断是否进行gridsearch寻优，是则对获取数据进行整理\n",
    "            select_model = naivebayes(name)\n",
    "            grid_alpha = request.POST.get('naivebayes_alpha_grid')\n",
    "            gs_para = {'alpha': grid_alpha,}\n",
    "            gridsearch_para = grid_para_split(gs_para,request)\n",
    "        else:\n",
    "            if name == 'GaussianNB':\n",
    "                select_model = naivebayes(name)\n",
    "            else:\n",
    "                select_model = naivebayes(name,Alpha=alpha)\n",
    "    elif select_child_model == 'svm':\n",
    "        select_model_name = 'SVM'\n",
    "        kernel = request.POST.get('svm_kernel')\n",
    "        if grid == \"G\":\n",
    "            select_model = svm(kernels=kernel)\n",
    "            grid_c,grid_degree,grid_coef,grid_gamma = request.POST.get('svm_c_grid'),\\\n",
    "                                       request.POST.get('svm_degree_grid'), \\\n",
    "                                       request.POST.get('svm_coef_grid'), \\\n",
    "                                       request.POST.get('svm_gamma_grid')\n",
    "            gs_para = {\n",
    "                'C':grid_c,\n",
    "                'degree': grid_degree,\n",
    "                'coef0': grid_coef,\n",
    "                'gamma': grid_gamma,\n",
    "            }\n",
    "            gridsearch_para = grid_para_split(gs_para,request)\n",
    "        else:\n",
    "            c, degree, coef, gamma = float(request.POST.get('svm_c')), \\\n",
    "                                       request.POST.get('svm_degree'), \\\n",
    "                                       request.POST.get('svm_coef'), \\\n",
    "                                       request.POST.get('svm_gamma')\n",
    "            if kernel == 'linear':\n",
    "                select_model = svm(kernels=kernel, c=c)\n",
    "            elif kernel == 'poly':\n",
    "                degree, coef = int(degree), float(coef)\n",
    "                select_model = svm(kernels=kernel, degrees=degree, c=c, coef=coef, Gamma=gamma)\n",
    "            elif kernel == 'sigmoid':\n",
    "                coef = float(coef)\n",
    "                select_model = svm(kernels=kernel, c=c, coef=coef, Gamma=gamma)\n",
    "            else:\n",
    "                select_model = svm(kernels=kernel, c=c, Gamma=gamma)\n",
    "\n",
    "    elif select_child_model == 'randomforest':\n",
    "        select_model_name = 'RandomForest'\n",
    "        criterion,max_features = request.POST.get('randomforest_criterion'),\\\n",
    "                                 request.POST.get('randomforest_max_features'),\n",
    "        if grid == \"G\":\n",
    "            select_model = randomforest(Criterion=criterion,Max_features=max_features)\n",
    "            max_depth_grid, min_samples_split_grid, min_samples_leaf_grid, n_estimators_grid = \\\n",
    "                request.POST.get('randomforest_max_depth_grid'), \\\n",
    "                request.POST.get('randomforest_min_samples_split_grid'), \\\n",
    "                request.POST.get('randomforest_min_samples_leaf_grid'), \\\n",
    "                request.POST.get('randomforest_n_estimators_grid')\n",
    "\n",
    "            gs_para = {\n",
    "                'max_depth': max_depth_grid,\n",
    "                'min_samples_split': min_samples_split_grid,\n",
    "                'min_samples_leaf': min_samples_leaf_grid,\n",
    "                'n_estimators': n_estimators_grid,\n",
    "            }\n",
    "            gridsearch_para = grid_para_split(gs_para, request,['int']*4)\n",
    "        else:\n",
    "            max_depth, min_samples_split, min_samples_leaf, n_estimators = request.POST.get('randomforest_max_depth'), \\\n",
    "                                               request.POST.get('randomforest_min_samples_split'), \\\n",
    "                                               request.POST.get('randomforest_min_samples_leaf'), \\\n",
    "                                               int(request.POST.get('randomforest_n_estimators'))\n",
    "            max_depth, min_samples_split, min_samples_leaf, max_features = \\\n",
    "                surv_para_group(max_depth, min_samples_split, min_samples_leaf, max_features)\n",
    "            select_model = randomforest(Criterion=criterion,Max_depth=max_depth,Min_samples_split=min_samples_split,\n",
    "                                        Min_samples_leaf=min_samples_leaf,Max_features=max_features,\n",
    "                                        N_estimators=n_estimators)\n",
    "\n",
    "    elif select_child_model == 'logistic':\n",
    "        select_model_name = 'Logistic'\n",
    "        penalty, solver, fit_intercept = request.POST.get('logistic_penalty'), \\\n",
    "                                                        request.POST.get('logistic_solver'), \\\n",
    "                                                        bool(request.POST.get('logistic_fit_intercept')),\n",
    "        if grid == 'G':\n",
    "            select_model = logistic_reg(Penalty=penalty,Fit_intercept=fit_intercept, Solver=solver)\n",
    "            C_grid = request.POST.get('logistic_C_grid')\n",
    "            gs_para = {'C': C_grid,}\n",
    "            gridsearch_para = grid_para_split(gs_para, request)\n",
    "        else:\n",
    "            C = request.POST.get('logistic_C')\n",
    "            C = float(C)\n",
    "            select_model = logistic_reg(Penalty=penalty, CC=C, Fit_intercept=fit_intercept, Solver=solver)\n",
    "\n",
    "    elif select_child_model == 'knn':\n",
    "        select_model_name = 'KNN'\n",
    "        algorithm, metric, weights, n_neighbors = request.POST.get('knn_algorithm'), \\\n",
    "                                                                request.POST.get('knn_metric'), \\\n",
    "                                                                request.POST.get('knn_weights'), \\\n",
    "                                                                int(request.POST.get('knn_n_neighbors')),\n",
    "        if grid == \"G\":\n",
    "            select_model = kneighbors(Weight=weights,Agorithm=algorithm, Metric=metric)\n",
    "            n_neighbors_grid = request.POST.get('knn_n_neighbors_grid')\n",
    "            gs_para = {'n_neighbors': n_neighbors_grid, }\n",
    "            gridsearch_para = grid_para_split(gs_para, request)\n",
    "        else:\n",
    "            n_neighbors = request.POST.get('knn_n_neighbors')\n",
    "            select_model = kneighbors(Weight=weights, Agorithm=algorithm, Metric=metric,N_neighbors=n_neighbors)\n",
    "    elif select_child_model == 'xgboost':\n",
    "        select_model_name = 'XGBoost'\n",
    "        subsample, colsample_bytree,reg_alpha, reg_lambda = float(request.POST.get('xgboost_subsample')),\\\n",
    "                                                            float(request.POST.get('xgboost_colsample_bytree')), \\\n",
    "                                                            float(request.POST.get('xgboost_reg_alpha')), \\\n",
    "                                                            float(request.POST.get('xgboost_reg_lambda'))\n",
    "        if grid == 'G':\n",
    "            select_model = xgboost(Subsample=subsample, Colsample_bytree=colsample_bytree, Reg_alpha=reg_alpha,\n",
    "                                   Reg_lambda=reg_lambda)\n",
    "            learning_rate_grid, n_estimators_grid, min_child_weight_grid, Gamma_grid = \\\n",
    "                request.POST.get('xgboost_learning_rate_grid'), \\\n",
    "                request.POST.get('xgboost_n_estimators_grid'), \\\n",
    "                request.POST.get('xgboost_min_child_weight_grid'), \\\n",
    "                request.POST.get('xgboost_Gamma_grid')\n",
    "\n",
    "            gs_para = {\n",
    "                'learning_rate': learning_rate_grid,\n",
    "                'n_estimators': (n_estimators_grid),\n",
    "                'min_child_weight':(min_child_weight_grid),\n",
    "                'Gamma': Gamma_grid\n",
    "            }\n",
    "            gridsearch_para = grid_para_split(gs_para, request,['float','int','int','float'])\n",
    "            print('gridsearch_para: ',gridsearch_para)\n",
    "\n",
    "        else:\n",
    "            learning_rate, n_estimators, min_child_weight, Gamma, = float(request.POST.get('xgboost_learning_rate')), \\\n",
    "                                    int(request.POST.get('xgboost_n_estimators')), \\\n",
    "                                    int(request.POST.get('xgboost_min_child_weight')), \\\n",
    "                                    float(request.POST.get('xgboost_Gamma'))\n",
    "            select_model = xgboost(Learning_rate=learning_rate, N_estimators=n_estimators,\n",
    "                                   Min_child_weight=min_child_weight,\n",
    "                                   Subsample=subsample, Colsample_bytree=colsample_bytree, Gamma=Gamma,\n",
    "                                   Reg_alpha=reg_alpha,\n",
    "                                   Reg_lambda=reg_lambda)\n",
    "\n",
    "\n",
    "    elif select_child_model == 'lightgbm':\n",
    "        select_model_name = 'lightGBM'\n",
    "        boosting_type, reg_alpha, reg_lambda, min_child_samples, subsample, = \\\n",
    "            request.POST.get('lightgbm_boosting_type'), \\\n",
    "            float(request.POST.get('lightgbm_reg_alpha')), \\\n",
    "            float(request.POST.get('lightgbm_reg_lambda')), \\\n",
    "            int(request.POST.get('lightgbm_min_child_samples')), \\\n",
    "            float(request.POST.get('lightgbm_subsample'))\n",
    "        if grid == 'G':\n",
    "            select_model = lightgbm(Boosting_type=boosting_type, Min_child_samples=min_child_samples,\n",
    "                                    Reg_alpha=reg_alpha, Reg_lambda=reg_lambda,Subsample=subsample,)\n",
    "            colsample_bytree_grid,learning_rate_grid, n_estimators_grid,num_leaves_grid, max_depth_grid = \\\n",
    "                (request.POST.get('lightgbm_colsample_bytree_grid')), \\\n",
    "                (request.POST.get('lightgbm_learning_rate_grid')), \\\n",
    "                (request.POST.get('lightgbm_n_estimators_grid')), \\\n",
    "                (request.POST.get('lightgbm_num_leaves_grid')), \\\n",
    "                (request.POST.get('lightgbm_max_depth_grid'))\n",
    "            gs_para = {\n",
    "                'colsample_bytree': colsample_bytree_grid,\n",
    "                'learning_rate': learning_rate_grid,\n",
    "                'n_estimators': n_estimators_grid,\n",
    "                'num_leaves': num_leaves_grid,\n",
    "                'max_depth': max_depth_grid\n",
    "            }\n",
    "            gridsearch_para = grid_para_split(gs_para, request,['float','float','int','int','int'])\n",
    "        else:\n",
    "            colsample_bytree, learning_rate, n_estimators,num_leaves, max_depth = \\\n",
    "                float(request.POST.get('lightgbm_colsample_bytree')), \\\n",
    "                float(request.POST.get('lightgbm_learning_rate')), \\\n",
    "                int(request.POST.get('lightgbm_n_estimators')), \\\n",
    "                int(request.POST.get('lightgbm_num_leaves')), \\\n",
    "                int(request.POST.get('lightgbm_max_depth'))\n",
    "            select_model = lightgbm(Boosting_type=boosting_type,N_estimators=n_estimators,\n",
    "                                    Min_child_samples=min_child_samples,Reg_alpha=reg_alpha,Reg_lambda=reg_lambda,\n",
    "                                    Subsample=subsample,Colsample_bytree=colsample_bytree,Num_leaves=num_leaves,\n",
    "                                    Max_depth=max_depth,Learning_rate=learning_rate)\n",
    "    elif select_child_model == 'adaboost':\n",
    "        select_model_name = 'Adaboost'\n",
    "        algorithm = request.POST.get('adaboost_algorithm')\n",
    "        if grid == 'G':\n",
    "            select_model = adaboost( Algorithm=algorithm,)\n",
    "            n_estimators_grid, learning_rate_grid, max_depth_grid = (request.POST.get('adaboost_n_estimators_grid')), \\\n",
    "                                                                (request.POST.get('adaboost_learning_rate_grid')), \\\n",
    "                                                                (request.POST.get('adaboost_max_depth_grid'))\n",
    "            gs_para = {\n",
    "                'learning_rate': learning_rate_grid,\n",
    "                'n_estimators': n_estimators_grid,\n",
    "                'max_depth': max_depth_grid\n",
    "            }\n",
    "            gridsearch_para = grid_para_split(gs_para, request, ['int', 'float', 'int'])\n",
    "        else:\n",
    "            n_estimators, learning_rate, max_depth = int(request.POST.get('adaboost_n_estimators')), \\\n",
    "                                                     float(request.POST.get('adaboost_learning_rate')), \\\n",
    "                                                     int(request.POST.get('adaboost_max_depth'))\n",
    "            select_model = adaboost(N_estimators=n_estimators, Learning_rate=learning_rate,Algorithm=algorithm,Max_depth=max_depth)\n",
    "    elif select_child_model == 'decisiontree':\n",
    "        select_model_name = 'DecisionTree'\n",
    "        criterion, splitter,max_features =  request.POST.get('decisiontree_criterion'),\\\n",
    "                                            request.POST.get('decisiontree_splitter'), \\\n",
    "                                            request.POST.get('decisiontree_max_features')\n",
    "        if grid == 'G':\n",
    "            select_model = decisiontree(Criterion=criterion, Splitter=splitter, Max_features=max_features)\n",
    "            max_depth_grid, min_samples_split_grid, min_samples_leaf_grid = \\\n",
    "                request.POST.get('decisiontree_max_depth_grid'), \\\n",
    "                request.POST.get('decisiontree_min_samples_split_grid'), \\\n",
    "                request.POST.get('decisiontree_min_samples_leaf_grid')\n",
    "            gs_para = {\n",
    "                'max_depth': max_depth_grid,\n",
    "                'min_samples_split': min_samples_split_grid,\n",
    "                'min_samples_leaf': min_samples_leaf_grid\n",
    "            }\n",
    "            gridsearch_para = grid_para_split(gs_para, request,['int','float','int'])\n",
    "        else:\n",
    "            max_depth, min_samples_split, min_samples_leaf = \\\n",
    "                                                            request.POST.get('decisiontree_max_depth'), \\\n",
    "                                                            request.POST.get('decisiontree_min_samples_split'), \\\n",
    "                                                            request.POST.get('decisiontree_min_samples_leaf')\n",
    "            max_depth, min_samples_split, min_samples_leaf, max_features = \\\n",
    "                surv_para_group(max_depth, min_samples_split, min_samples_leaf, max_features)\n",
    "            select_model = decisiontree(Criterion=criterion,Splitter=splitter,Max_depth=max_depth,\n",
    "                                        Min_samples_split=min_samples_split,Min_samples_leaf=min_samples_leaf,\n",
    "                                        Max_features=max_features)\n",
    "    else:\n",
    "        select_model_name = 'GBDT'\n",
    "        criterion, loss, subsample, max_features, = request.POST.get('gbdt_criterion'), \\\n",
    "                         request.POST.get('gbdt_loss'), \\\n",
    "                         float(request.POST.get('gbdt_subsample')), \\\n",
    "                         request.POST.get('gbdt_max_features'),\n",
    "        if grid == 'G':\n",
    "            select_model = gbdt(Loss=loss,Subsample=subsample,Criterion=criterion,Max_features=max_features)\n",
    "            learning_rate_grid,min_samples_split_grid, min_samples_leaf_grid, max_depth_grid,n_estimators_grid =  \\\n",
    "                         (request.POST.get('gbdt_learning_rate_grid')), \\\n",
    "                         request.POST.get('gbdt_min_samples_split_grid'), \\\n",
    "                         request.POST.get('gbdt_min_samples_leaf_grid'), \\\n",
    "                         request.POST.get('gbdt_max_depth_grid'), \\\n",
    "                         (request.POST.get('gbdt_n_estimators_grid')),\n",
    "            gs_para = {\n",
    "                'learning_rate': learning_rate_grid,\n",
    "                'min_samples_split': min_samples_split_grid,\n",
    "                'min_samples_leaf': min_samples_leaf_grid,\n",
    "                'max_depth':max_depth_grid,\n",
    "                'n_estimators':n_estimators_grid\n",
    "\n",
    "            }\n",
    "            gridsearch_para = grid_para_split(gs_para, request,['float','int','int','int','int'])\n",
    "        else:\n",
    "            learning_rate,min_samples_split, min_samples_leaf, max_depth,n_estimators =  \\\n",
    "                         float(request.POST.get('gbdt_learning_rate')), \\\n",
    "                         request.POST.get('gbdt_min_samples_split'), \\\n",
    "                         request.POST.get('gbdt_min_samples_leaf'), \\\n",
    "                         request.POST.get('gbdt_max_depth'), \\\n",
    "                         int(request.POST.get('gbdt_n_estimators')),\n",
    "            max_depth, min_samples_split, min_samples_leaf, max_features = \\\n",
    "                surv_para_group(max_depth, min_samples_split, min_samples_leaf, max_features)\n",
    "            select_model = gbdt(Loss=loss,Learning_rate=learning_rate,Subsample=subsample,\n",
    "                                Criterion=criterion,Min_samples_split=min_samples_split,Max_features=max_features,\n",
    "                                Min_samples_leaf=min_samples_leaf,Max_depth=max_depth,Validation_fraction=validation_fraction,\n",
    "                                N_estimators=n_estimators)\n",
    "    return select_model, select_model_name,gridsearch_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_para_split(paras,request,type=['float']*6):\n",
    "    from django.contrib import messages\n",
    "    para_lsts = {}\n",
    "    i = 0\n",
    "    for para_key,para in paras.items():\n",
    "        if para == None:\n",
    "            continue\n",
    "        if len(para.split(\":\")) != 3:\n",
    "            title = 'Invalid input.Please use the \"from:to:step\" format for parameter input.'\n",
    "            messages.success(request, title)\n",
    "            return render(request, \"analysis.html\")\n",
    "        if type[i] == 'int':\n",
    "            try:\n",
    "                para_from = int(para.split(\":\")[0])\n",
    "                para_to = int(para.split(\":\")[1])\n",
    "                para_step = int(para.split(\":\")[2])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                title = 'Invalid input.Please use the \"1:10:1\" format for parameter input.'\n",
    "                messages.success(request, title)\n",
    "                return render(request, \"analysis.html\")\n",
    "            para_from,para_to,para_step = int(para_from),int(para_to),int(para_step)\n",
    "            para_lst = np.arange(para_from, para_to+1, para_step)\n",
    "        else:\n",
    "            try:\n",
    "                para_from = float(para.split(\":\")[0])\n",
    "                para_to = float(para.split(\":\")[1])\n",
    "                para_step = float(para.split(\":\")[2])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                title = 'Invalid input.Please use the \"1:10:1\" format for parameter input.'\n",
    "                messages.success(request, title)\n",
    "                return render(request, \"analysis.html\")\n",
    "            para_lst = np.arange(para_from, para_to+0.01, para_step) #左闭右开\n",
    "        para_lsts[para_key] = para_lst\n",
    "        i = i + 1\n",
    "    return para_lsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_float_to_int(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_float_to_int(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_float_to_int(item) for item in obj]\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.astype(int)\n",
    "    elif isinstance(obj, float):\n",
    "        return int(obj)\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46934adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2d433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
